#!/opt/python-venv/duplicity/bin/python
# -*- coding: utf-8; py-indent-offset: 4 -*-
#
# Author:  Linuxfabrik GmbH, Zurich, Switzerland
# Contact: info (at) linuxfabrik (dot) ch
#          https://www.linuxfabrik.ch/
# License: The Unlicense, see https://unlicense.org/.

import argparse # pylint: disable=C0413
import json # pylint: disable=C0413
import logging # pylint: disable=C0413
import os # pylint: disable=C0413
import re # pylint: disable=C0413
import subprocess # pylint: disable=C0413
import sys # pylint: disable=C0413
import time # pylint: disable=C0413

from traceback import format_exc # pylint: disable=C0413


__author__ = 'Linuxfabrik GmbH, Zurich/Switzerland'
__version__ = '2022032904'

DESCRIPTION = 'Do a massive parallel backup on a Swift storage backend with duplicity.'


def parse_args():
    """Parse command line arguments using argparse.
    """
    parser = argparse.ArgumentParser(description=DESCRIPTION)

    parser.add_argument(
        '-V', '--version',
        action='version',
        version='{0}: v{1} by {2}'.format('%(prog)s', __version__, __author__)
    )

    parser.add_argument(
        '--config',
        help='Path to JSON config file. Default: %(default)s',
        dest='CONFIG_FILE',
        default='/etc/duba/duba.json',
    )

    parser.add_argument(
        '--command',
        help='Command to run. Default: %(default)s',
        dest='COMMAND',
        default='backup',
        choices=[
            'backup',
        ]
    )

    return parser.parse_args()


def init_logging():
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)

    console_logger = logging.StreamHandler()
    console_logger.setLevel(logging.DEBUG)
    console_logger.setFormatter(logging.Formatter(
            '%(asctime)s %(levelname)s: duby.py - %(message)s', datefmt='%Y-%m-%d %H:%M:%S'
    ))
    logger.addHandler(console_logger)

    return logger


def load_config(config_file='/etc/duba/duba.json'):
    # load config file
    try:
        with open(config_file, 'r') as f:
            config = f.read()
    except IOError as e:
        logger.error(f'I/O error: {e.strerror} while opening or reading {config_file}')
        sys.exit(201)
    except:
        logger.error(f'Unknown error opening or reading {config_file}')
        sys.exit(202)
    # interpret config
    try:
        return json.loads(config)
    except json.JSONDecodeError as e:
        logger.error(f'JSON decode error: {e}')
        sys.exit(203)


def set_env(config, env=os.environ.copy()):
    # enrich the environment variables
    env['LC_ALL'] = 'C' # set cmd output to English, no matter what the user has choosen
    for key, value in config.items():
        env[key] = value
    return env


def do_backup(config):
    """Do a massive parallel backup using duplicity and swift as backend. After that, delete
       all backups older than the given retention time.
       This function works and is fast, but the code is not very good and could be improved later.
    """
    logger.info('Starting backup...')

    # count the number of logical processors to limit number of processes (taken from psutil)
    cpu_count = os.sysconf('SC_NPROCESSORS_ONLN')
    running_procs = []
    env = set_env(config.get('env', {}))
    global_retc = 0

    # iterate over backup dirs and spawn processes
    for src in config.get('backup_sources', []):
        filelist = []
        if src.get('divide', False):
            # divide the source dir:
            # do not backup the whole dir, but every item on the first level individually
            logger.debug(f"Dividing the source dir {src.get('path', '')}")
            for root, dirs, files in os.walk(src.get('path', '')):
                for f in files:
                    filelist.append(os.path.join(root, f))
                for f in dirs:
                    filelist.append(os.path.join(root, f))
                # break at first directory level
                break
        else:
            filelist.append(src.get('path', ''))

        for f in filelist:
            # build the duplicity backup command line
            cmd = ['ionice', '--class', '3']
            cmd += ['nice', '--adjustment', '19']
            cmd += ['duplicity']
            cmd += ['--asynchronous-upload']
            cmd += ['--backend-retry-delay', '60']
            cmd += ['--cf-backend', f"{config.get('backend', 'swift')}"]
            cmd += ['--copy-links']
            cmd += ['--encrypt-key', f"{config.get('gpg_encrypt_local_key', '')}"]
            cmd += ['--encrypt-key', f"{config.get('gpg_encrypt_master_key', '')}"]
            # global excludes
            for exclude in config.get('backup_excludes', []):
                cmd += ['--exclude', f"{exclude}"]
            # excludes for this directory
            for exclude in src.get('excludes', []):
                cmd += ['--exclude', f"{exclude}"]
            cmd += ['--exclude-other-filesystems']
            cmd += ['--full-if-older-than', f"{config.get('retention_time', '30D')}"]
            logfile = re.sub(r'[^A-Za-z0-9]+', '-', f)
            if logfile[0] == '-':
                # cut the first "-"
                logfile = logfile[1:]
            cmd += ['--log-file', f"{config.get('logdir', '/var/log/duplicity')}/{logfile}.log"]
            cmd += ['--log-timestamp']
            cmd += ['--num-retries', '5']
            cmd += ['--verbosity', f"{config.get('loglevel', 'notice')}"]
            cmd += ['--volsize', '200']
            cmd += [f"{f}"]
            cmd += [f"{config.get('backup_dest', '')}{f}"]

            logger.info(f"Running: {' '.join(cmd)}")

            # start duplicity in the background
            # * start n processes: start up to (cpu-cores + 1) nice processes to backup as
            #   much as possible
            # * be as nice as possible: only when the machine is busy, the script is slower
            # * be asynchronous: uploading volumes while packaging new ones saves a lot of time
            # * use compression: saves money on external storages; bottleneck is always your uplink
            # and return immediately
            try:
                running_procs.append(subprocess.Popen(cmd, env=env))
            except OSError as e:
                logger.error(f'OS Error "{e.errno} {e.strerror}" calling command "{cmd}"')
                sys.exit(205)
            except ValueError as e:
                logger.error(f'Value Error "{e}" calling command "{cmd}"')
                sys.exit(206)
            except e:
                logger.error(f'Unknown error "{e}" while calling command "{cmd}"')
                sys.exit(207)

            # don't start more than max cpu processes
            # https://stackoverflow.com/questions/16807603/python-non-blocking-non-defunct-process
            # https://docs.python.org/3/library/subprocess.html#subprocess.Popen.poll
            while True:
                time.sleep(1)
                for proc in running_procs:
                    retc = proc.poll()
                    if retc is not None:
                        # there is a retc, so process has finished
                        proc.terminate()
                        try:
                            proc.communicate(timeout=30)
                        except subprocess.TimeoutExpired:
                            proc.kill()
                            proc.communicate()
                        running_procs.remove(proc)
                        if retc != 0 and retc != 13:
                            # just ignore missing directories (backup_dir_doesnt_exist = 13)
                            global_retc = retc
                        logger.debug('Process terminated')
                if len(running_procs) <= cpu_count:
                    # continue in outer for loop and launch another process
                    break

    # wait here for all processes to finish
    logger.debug('All duplicity processes started, waiting for them to finish.')
    while True:
        time.sleep(1)
        for proc in running_procs:
            retc = proc.poll()
            if retc is not None:
                # there is a retc, so process has finished
                proc.terminate()
                try:
                    proc.communicate(timeout=30)
                except subprocess.TimeoutExpired:
                    proc.kill()
                    proc.communicate()
                running_procs.remove(proc)
                logger.debug('Process terminated')
        if not running_procs:
            # all processes finished, exit loop
            break

    logger.info('Starting cleanup...')
    """Delete all backup sets older than the given time. Old backup sets will not be deleted if
       backup sets newer than time depend on them. Note, this action cannot be combined with backup
       or other actions, such as cleanup. Note also that --force will be needed to delete the files
       instead of just listing them.
    """

    # iterate over backup dirs and spawn processes
    for src in config.get('backup_sources', []):
        filelist = []
        if src.get('divide', False):
            # divide the source dir:
            # do not backup the whole dir, but every item on the first level individually
            logger.debug(f"Dividing the source dir {src.get('path', '')}")
            for root, dirs, files in os.walk(src.get('path', '')):
                for f in files:
                    filelist.append(os.path.join(root, f))
                for f in dirs:
                    filelist.append(os.path.join(root, f))
                # break at first directory level
                break
        else:
            filelist.append(src.get('path', ''))

        for f in filelist:
            # build the duplicity command line
            cmd = ['nice', '--adjustment', '19']
            cmd += ['duplicity']
            cmd += ['remove-older-than', f"{config.get('retention_time', '30D')}"]
            cmd += ['--backend-retry-delay', '60']
            cmd += ['--force']
            logfile = re.sub(r'[^A-Za-z0-9]+', '-', f)
            if logfile[0] == '-':
                # cut the first "-"
                logfile = logfile[1:]
            cmd += ['--log-file', f"{config.get('logdir', '/var/log/duplicity')}/{logfile}.log"]
            cmd += ['--log-timestamp']
            cmd += ['--num-retries', '5']
            cmd += ['--verbosity', f"{config.get('loglevel', 'notice')}"]
            cmd += [f"{config.get('backup_dest', '')}{f}"]

            logger.info(f"Running: {' '.join(cmd)}")

            # start duplicity in the background
            # * start n processes: start up to (cpu-cores + 1) nice processes to backup as
            #   much as possible
            # * be as nice as possible: only when the machine is busy, the script is slower
            # * be asynchronous: uploading volumes while packaging new ones saves a lot of time
            # * use compression: saves money on external storages; bottleneck is always your uplink
            # and return immediately
            try:
                running_procs.append(subprocess.Popen(cmd, env=env))
            except OSError as e:
                logger.error(f'OS Error "{e.errno} {e.strerror}" calling command "{cmd}"')
                sys.exit(205)
            except ValueError as e:
                logger.error(f'Value Error "{e}" calling command "{cmd}"')
                sys.exit(206)
            except e:
                logger.error(f'Unknown error "{e}" while calling command "{cmd}"')
                sys.exit(207)

            # don't start more than max cpu processes
            # https://stackoverflow.com/questions/16807603/python-non-blocking-non-defunct-process
            # https://docs.python.org/3/library/subprocess.html#subprocess.Popen.poll
            while True:
                time.sleep(0.5)
                for proc in running_procs:
                    retc = proc.poll()
                    if retc is not None:
                        # there is a retc, so process has finished
                        proc.terminate()
                        try:
                            proc.communicate(timeout=30)
                        except subprocess.TimeoutExpired:
                            proc.kill()
                            proc.communicate()
                        running_procs.remove(proc)
                        logger.debug('Process terminated')
                if len(running_procs) <= cpu_count:
                    # continue in outer for loop and launch another process
                    break

    # wait here for all processes to finish
    logger.debug('All duplicity processes started, waiting for them to finish.')
    while True:
        time.sleep(0.5)
        for proc in running_procs:
            retc = proc.poll()
            if retc is not None:
                # there is a retc, so process has finished
                proc.terminate()
                try:
                    proc.communicate(timeout=30)
                except subprocess.TimeoutExpired:
                    proc.kill()
                    proc.communicate()
                running_procs.remove(proc)
                logger.debug('Process terminated')
        if not running_procs:
            # all processes finished, exit loop
            break

    logger.info('Backup done.')

    # return last exit code
    sys.exit(global_retc)


def main():
    """The main function. Hier spielt die Musik.
    """

    # parse the command line, exit if it fails
    try:
        args = parse_args()
    except SystemExit:
        sys.exit(221)

    global logger
    config = load_config(args.CONFIG_FILE)
    logger = init_logging()

    try:
        os.mkdir(config.get('logdir', '/var/log/duplicity'), 0o640)
    except OSError as error: 
        pass

    if args.COMMAND == 'backup':
        do_backup(config)


if __name__ == '__main__':
    try:
        main()
    except Exception:   # pylint: disable=W0703
        print(format_exc().replace("<", "'").replace(">", "'"))
        sys.exit(222)
